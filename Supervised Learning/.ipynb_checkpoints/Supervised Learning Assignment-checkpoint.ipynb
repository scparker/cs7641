{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Supervised Learning Assignment\n",
    "\n",
    "####  S. Parker 2016\n",
    "\n",
    "This notebook will examine the phishing dataset with decision trees.  It will look at the effectiveness of the decision trees relative to:\n",
    "\n",
    "*  Levels in the decision tree\n",
    "*  Number of training samples\n",
    "*  Bias vs variance calculations\n",
    "*  Performance metrics (memory used, time to fit, time to predict)\n",
    "\n",
    "Also explored will be the effect of pre-pruning the data set and how this affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fe22ae848a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pandas as pd\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import timeit\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Image \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Control variables for simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_test_split = .65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Helper function to allow us to get the size of the learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from numbers import Number\n",
    "from collections import Set, Mapping, deque\n",
    "\n",
    "try: # Python 2\n",
    "    zero_depth_bases = (basestring, Number, xrange, bytearray)\n",
    "    iteritems = 'iteritems'\n",
    "except NameError: # Python 3\n",
    "    zero_depth_bases = (str, bytes, Number, range, bytearray)\n",
    "    iteritems = 'items'\n",
    "\n",
    "def getsize(obj_0):\n",
    "    \"\"\"Recursively iterate to sum size of object & members.\"\"\"\n",
    "    def inner(obj, _seen_ids = set()):\n",
    "        obj_id = id(obj)\n",
    "        if obj_id in _seen_ids:\n",
    "            return 0\n",
    "        _seen_ids.add(obj_id)\n",
    "        size = sys.getsizeof(obj)\n",
    "        if isinstance(obj, zero_depth_bases):\n",
    "            pass # bypass remaining control flow and return\n",
    "        elif isinstance(obj, (tuple, list, Set, deque)):\n",
    "            size += sum(inner(i) for i in obj)\n",
    "        elif isinstance(obj, Mapping) or hasattr(obj, iteritems):\n",
    "            size += sum(inner(k) + inner(v) for k, v in getattr(obj, iteritems)())\n",
    "        # Check for custom object instances - may subclass above too\n",
    "        if hasattr(obj, '__dict__'):\n",
    "            size += inner(vars(obj))\n",
    "        if hasattr(obj, '__slots__'): # can have __slots__ with __dict__\n",
    "            size += sum(inner(getattr(obj, s)) for s in obj.__slots__ if hasattr(obj, s))\n",
    "        return size\n",
    "    return inner(obj_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and prepare training set #1\n",
    "\n",
    "For this assignment I choose the following two data sets:\n",
    "    \n",
    "*  Phishing data set - looks at various attributes of a website address and compute whether the site if a phishing site or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Load ARFF file\n",
    "dataset_1_name = \"Phishing\"\n",
    "\n",
    "arff_all = arff.load(open('datasets/phishing/Training Dataset.arff.txt'), 'rb')\n",
    "\n",
    "#  Put data into dataframe\n",
    "df_1_all = pd.DataFrame(arff_all[\"data\"], columns=pd.DataFrame(arff_all[\"attributes\"])[0])\n",
    "\n",
    "#  Split into training and testing sets\n",
    "split_ratio = .65\n",
    "split_point = int(len(df_1_all) * split_ratio)\n",
    "\n",
    "df_training = df_1_all[0:split_point]\n",
    "df_testing  = df_1_all[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Vary Decision Tree Depth to see effect on training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(df_training.values[:,0:-2], df_training.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                     feature_names=df_training.columns.values,  \n",
    "                     class_names=[\"False\", \"True\"],  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "fit_run_time = []\n",
    "predict_run_time= []\n",
    "memory_usage = []\n",
    "\n",
    "depth_range = range(1,25)\n",
    "\n",
    "for depth in depth_range:\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth)\n",
    "    fit_run_time.append(timeit.timeit(\"clf.fit(df_training.values[:,0:-2], df_training.values[:,-1])\", \n",
    "                    \"from __main__ import clf, df_training\",\n",
    "                     number = 5))\n",
    "    \n",
    "    memory_usage.append(getsize(clf))\n",
    "    \n",
    "    training_accuracy.append(clf.score(df_training.values[:,0:-2], df_training.values[:,-1]))\n",
    "    testing_accuracy.append(clf.score(df_testing.values[:,0:-2], df_testing.values[:,-1]))\n",
    "    \n",
    "    predict_run_time.append(timeit.timeit(\"clf.score(df_testing.values[:,0:-2], df_testing.values[:,-1])\",\n",
    "                                          \"from __main__ import clf, df_testing\",\n",
    "                                          number=5))\n",
    "    \n",
    "plt.figure(figsize=(20,10))    \n",
    "    \n",
    "plt.subplot(221)\n",
    "plt.plot(depth_range, training_accuracy)\n",
    "plt.plot(depth_range, testing_accuracy)\n",
    "plt.title(\"Phishing Dataset - Depth vs. Accuracy (Entropy)\")\n",
    "plt.xlabel(\"Decision Tree Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Training Set\", \"Testing Set\"], loc=2)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title(\"Phishing Dataset - Depth vs. Fit Runtime\")\n",
    "plt.plot(depth_range, np.array(fit_run_time) * 1000)\n",
    "plt.ylabel(\"Run Time (milliseconds)\")\n",
    "plt.xlabel(\"Decision Tree Depth\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title(\"Phishing Dataset - Depth vs. Predict Runtime On Test Set\")\n",
    "plt.plot(depth_range, np.array(predict_run_time) * 1000)\n",
    "plt.ylabel(\"Run Time (milliseconds)\")\n",
    "plt.xlabel(\"Decision Tree Depth\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title(\"Phishing Dataset - Depth vs. Predict Runtime On Test Set\")\n",
    "plt.plot(depth_range, memory_usage)\n",
    "plt.ylabel(\"Run Time (milliseconds)\")\n",
    "plt.xlabel(\"Decision Tree Depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "\n",
    "percent_of_training_data = np.arange(.05,1.0,.05)\n",
    "\n",
    "for percent in percent_of_training_data:\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "#    clf = ensemble.AdaBoostClassifier()\n",
    "#    clf = svm.SVC()\n",
    "#    clf = neighbors.NearestNeighbors()\n",
    "    clf.fit(df_training.values[0:int(percent * len(df_training)),0:-2], \\\n",
    "            df_training.values[0:int(percent * len(df_training)),-1])\n",
    "    \n",
    "    training_accuracy.append(clf.score(df_training.values[:,0:-2], df_training.values[:,-1]))\n",
    "    testing_accuracy.append(clf.score(df_testing.values[:,0:-2], df_testing.values[:,-1]))\n",
    "    \n",
    "    predict_run_time.append(timeit.timeit(\"clf.score(df_testing.values[:,0:-2], df_testing.values[:,-1])\",\n",
    "                                          \"from __main__ import clf, df_testing\",\n",
    "                                          number=5))\n",
    "    \n",
    "plt.plot(percent_of_training_data, training_accuracy)\n",
    "plt.plot(percent_of_training_data, testing_accuracy)\n",
    "plt.title(\"Phishing Dataset - Training Data Samples vs. Accuracy (Entropy)\")\n",
    "plt.xlabel(\"Fraction of Training Data Sample Set\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Training Set\", \"Testing Set\"], loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "\n",
    "percent_of_training_data = np.arange(.05,1.0,.05)\n",
    "\n",
    "for percent in percent_of_training_data:\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    clf.fit(df_training.values[0:int(percent * len(df_training)),0:-2], \\\n",
    "            df_training.values[0:int(percent * len(df_training)),-1])\n",
    "    \n",
    "    training_accuracy.append(clf.score(df_training.values[:,0:-2], df_training.values[:,-1]))\n",
    "    testing_accuracy.append(clf.score(df_testing.values[:,0:-2], df_testing.values[:,-1]))\n",
    "    \n",
    "plt.plot(percent_of_training_data, training_accuracy)\n",
    "plt.plot(percent_of_training_data, testing_accuracy)\n",
    "plt.title(\"Phishing Dataset - Training Data Samples vs. Accuracy (Entropy)\")\n",
    "plt.xlabel(\"Fraction of Training Data Sample Set\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Training Set\", \"Testing Set\"], loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getsize(clf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
